{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naru289/Assignment-28/blob/main/M3_AST_28_Reinforcement_Learning_Q_Learning_C%20copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaSXA3KF57Ko"
      },
      "source": [
        "# Advanced Programme in Deep Learning (Foundations and Applications)\n",
        "## A Program by IISc and TalentSprint\n",
        "### Assignment: Reinforcement Learning - Q Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8abyi0q57Kr"
      },
      "source": [
        "## Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jq4Ny4Jm57Ks"
      },
      "source": [
        "At the end of the experiment, you will be able to :\n",
        "\n",
        "* understand Reinforcement learning\n",
        "* setup the OpenAI Gym environment\n",
        "* understand Q-learning Algorithm\n",
        "* implement Q-learning algorithm to solve Taxi environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emcLfpQ-hDl6"
      },
      "source": [
        "### Setup Steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWMVQWk58aXm"
      },
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"2237180\" #@param {type:\"string\"}"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwqosl928dBA"
      },
      "source": [
        "#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"6366871391\" #@param {type:\"string\"}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "GXbNUL2L6LoU",
        "outputId": "6f036e86-db74-4d8a-a3bb-738497d2502a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook= \"M3_AST_28_Reinforcement_Learning_Q_Learning_C\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "    from IPython.display import HTML, display\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "\n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getAnswer1() and getAnswer2() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id,\n",
        "              \"answer1\" : Answer1, \"answer2\" : Answer2, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_mentor_support\": Mentor_support}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://dlfa-iisc.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "\n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "\n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "# def getWalkthrough():\n",
        "#   try:\n",
        "#     if not Walkthrough:\n",
        "#       raise NameError\n",
        "#     else:\n",
        "#       return Walkthrough\n",
        "#   except NameError:\n",
        "#     print (\"Please answer Walkthrough Question\")\n",
        "#     return None\n",
        "\n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer1():\n",
        "  try:\n",
        "    if not Answer1:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Answer1\n",
        "  except NameError:\n",
        "    print (\"Please answer Question 1\")\n",
        "    return None\n",
        "\n",
        "def getAnswer2():\n",
        "  try:\n",
        "    if not Answer2:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Answer2\n",
        "  except NameError:\n",
        "    print (\"Please answer Question 2\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getId():\n",
        "  try:\n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup\n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId=2237180&recordId=2340\"></script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup completed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsjutCK457Kt"
      },
      "source": [
        "## Information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIxXmF-zDM4d"
      },
      "source": [
        "Machine Learning can be classified into:\n",
        "\n",
        "* Supervised learning\n",
        "* Unsupervised learning\n",
        "* Reinforcement learning\n",
        "\n",
        "<center>\n",
        "<img src=\"https://miro.medium.com/max/899/1*9Eu_-DDMZ_bP_t94_MMEYA.png\" width=500px/>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPM_q921EO00"
      },
      "source": [
        "### Reinforcement Learning (RL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zDfRUG8EfZQ"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://docs.aws.amazon.com/deepracer/latest/developerguide/images/deepracer-reinforcement-learning-overview.png\" width=500px/>\n",
        "</center>\n",
        "<br><br>\n",
        "\n",
        "In Reinforcement Learning, a software **agent** makes observations (**states**) and takes **actions** within an **environment**, and in return it receives **rewards**. Its objective is to learn to act in a way that will maximize its expected rewards over time. We can think of positive rewards as pleasure and negative rewards as pain. In short, the agent acts in the environment and learns by trial and error to maximize its pleasure and minimize its pain.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeUxjOROMkUP"
      },
      "source": [
        "### Introduction to OpenAI Gym"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJk-xVkONpWK"
      },
      "source": [
        "One of the challenges of Reinforcement Learning is that in order to train an agent, we first need to have a working environment. If we want to program an agent that will learn to play an Atari game, we will need an Atari game simulator.\n",
        "\n",
        "**OpenAI Gym** is a toolkit that provides a wide variety of simulated environments (Atari games, board games, 2D and 3D physical simulations, and so on), so we can train agents, compare them, or develop new RL algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example: Self-Driving Cab\n",
        "\n",
        "Here, the task is to teach a Taxi, or Cab, to pick up and drop off passengers at the right locations using the Q-Learning algorithm.\n",
        "\n",
        "<br>\n",
        "<center>\n",
        "<img src=\"https://cdn.iisc.talentsprint.com/AIAS/smartcab_animation.gif\" width=400px>\n",
        "</center>\n",
        "<br>\n",
        "\n",
        "There are four designated locations in the grid world indicated by ***Red***, ***Green***, ***Yellow***, and ***Blue***. When the episode starts, the taxi starts off at a random square and the passenger is at a random location. The taxi drives to the passenger's location, picks up the passenger, drives to the passenger's destination (another one of the four specified locations), and then drops off the passenger. Once the passenger is dropped off, the episode ends.\n",
        "\n",
        "Here are a few things that it needs to take care of:\n",
        "\n",
        "- Drop off the passenger to the right location\n",
        "- Save passenger's time by taking minimum time possible to drop off\n",
        "- Take care of passenger's safety and drive only on the road\n",
        "\n",
        "Let's see the details of different aspects, such as rewards, states, and actions, that needs to be considered while modeling an RL solution for this problem."
      ],
      "metadata": {
        "id": "TiqoGT-k7SE9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Actions**\n",
        "\n",
        "There are **6** discrete deterministic actions:\n",
        "\n",
        "- 0: move south\n",
        "- 1: move north\n",
        "- 2: move east\n",
        "- 3: move west\n",
        "- 4: pickup passenger\n",
        "- 5: drop off passenger"
      ],
      "metadata": {
        "id": "9-ub6asy9O2Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **States** (Observations)\n",
        "\n",
        "There are **500** discrete states\n",
        "\n",
        "$ = 25$ (taxi positions) $\\times 5$ (possible passenger locations) $\\times 4$ (destination locations)\n",
        "\n",
        "<br>\n",
        "\n",
        "Taxi positions: (25)\n",
        "\n",
        "$\\quad\\quad$<img src=\"https://cdn.iisc.talentsprint.com/AIAS/Taxi_location.png\" width=300px>\n",
        "\n",
        "\n",
        "Passenger locations: (5)\n",
        "\n",
        "- 0: R(red)\n",
        "- 1: G(green)\n",
        "- 2: Y(yellow)\n",
        "- 3: B(blue)\n",
        "- 4: in taxi\n",
        "\n",
        "Destinations: (4)\n",
        "\n",
        "- 0: R(red)\n",
        "- 1: G(green)\n",
        "- 2: Y(yellow)\n",
        "- 3: B(blue)\n",
        "\n",
        "<br>\n",
        "\n",
        "Each of these 500 states are represented by tuples of: (taxi_row, taxi_col, passenger_location, destination)."
      ],
      "metadata": {
        "id": "tudwj07vEWpd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Rewards**\n",
        "\n",
        "Few points to consider for rewards allocation:\n",
        "\n",
        "- The agent should receive a high positive reward for a successful dropoff because this behavior is highly desired\n",
        "\n",
        "- The agent should be penalized if it tries to drop off a passenger in wrong locations\n",
        "\n",
        "- The agent should get a slight negative reward for not making it to the destination after every time-step. \"Slight\" negative because it would be prefered to reach late instead of making wrong moves trying to reach to the destination as fast as possible\n",
        "\n",
        "Based on above points, the rewards are as follows:\n",
        "\n",
        "- $+20$ delivering passenger\n",
        "- $-10$ executing “pickup” and “drop-off” actions illegally\n",
        "- $-1$ per step unless other reward is triggered"
      ],
      "metadata": {
        "id": "kfn46a2WOHov"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import required packages"
      ],
      "metadata": {
        "id": "312UlBO63D6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import matplotlib as mpl\n",
        "mpl.rc('animation', html='jshtml')\n",
        "import random\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "SatLedJ21CJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List all the available environments\n",
        "gym.envs.registry.values()"
      ],
      "metadata": {
        "id": "HJCAP1Qi6fim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Environment\n",
        "\n",
        "An environment can be created using `gym.make()` function. After the environment is created, it must be initialized using the `reset()` method. This returns the first observation/state. Observations depend on the type of environment."
      ],
      "metadata": {
        "id": "TLWoSbnhQfs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Taxi environment\n",
        "env = gym.make(\"Taxi-v3\", render_mode=\"single_rgb_array\")\n",
        "\n",
        "# Set seed for reproducibility\n",
        "env.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "state_ = env.reset()\n",
        "state_"
      ],
      "metadata": {
        "id": "5iwPWcywbD7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In case of taxi environment, the state is an integer (0 - 499) that encodes the corresponding state space represented by tuple: (taxi_row, taxi_col, passenger_location, destination).\n",
        "\n",
        "The state tuple can be decoded with the `decode` method."
      ],
      "metadata": {
        "id": "_tXYiL0GTs8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode state\n",
        "tuple(env.decode(state_))      # (taxi row, taxi column, passenger index, destination index)"
      ],
      "metadata": {
        "id": "IdxZCT-8TUzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a function to visualize the environment."
      ],
      "metadata": {
        "id": "V1MmszMzVYUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to plot environment\n",
        "\n",
        "def plot_environment(env, figsize=(5,4)):\n",
        "    plt.figure(figsize=figsize)\n",
        "    img = env.render( )              # render() will render the frame/snapshot of environment in current state.\n",
        "                                     # We want render() to return the rendered image as a NumPy array, that's why\n",
        "                                     # we set render_mode=\"single_rgb_array\" while instantiating the environment\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    return img"
      ],
      "metadata": {
        "id": "jGKS7Sgahd6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_environment(env)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2elBqeTrSB9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above decoded state can be visualized in above plot."
      ],
      "metadata": {
        "id": "EM33pmWzV9cz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Action and State spaces\n",
        "print(\"Action Space {}\".format(env.action_space))\n",
        "print(\"State Space {}\".format(env.observation_space))"
      ],
      "metadata": {
        "id": "WKpU4X07a5gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **env.action_space**: gives the possible actions\n",
        "\n",
        "* **env.observation_space**: gives the no of states"
      ],
      "metadata": {
        "id": "_JrJOX663OJi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DITDo0g63Xz9"
      },
      "source": [
        "## The Q-Learning Algorithm\n",
        "\n",
        "**Q-Learning**\n",
        "\n",
        "Q-learning is an off-policy learning method, which means it doesn’t follow any policy to find the next action but instead picks the action based on a greedy fashion. A Q-table containing Q-values is created for the specific environment. As the agent chooses actions for each state, depending on the reward it receives for the action, the Q-value will update using the equation:\n",
        "\n",
        "$$NewQ(s, a) = Q(s, a) + \\alpha[R(s, a) + \\gamma\\ maxQ^{'}(s', a') - Q(s, a)]$$\n",
        "\n",
        "The above equation represents the following:\n",
        "\n",
        "$NewQ(s, a):$ new Q-value for that state and that action\n",
        "\n",
        "$Q(s, a):$ Current Q-value\n",
        "\n",
        "$\\alpha:$ Learning Rate\n",
        "\n",
        "$R(s, a):$ Reward for taking that action at that state\n",
        "\n",
        "$\\gamma:$ Discount Rate\n",
        "\n",
        "$maxQ^{'}(s', a'):$ Maximum expected future reward given the new s' and all possible actions at that new state\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The above equation states that the Q-value yielded from being at state $s$ and performing action $a$ is the immediate reward $R(s,a)$ plus the highest Q-value possible from the next state $s’$. Gamma here is the discount factor which controls the contribution of rewards further in the future.\n",
        "\n",
        "$Q(s’,a’)$ depends on $Q(s”, a”)$ which will then have a coefficient of gamma squared. So, the Q-value depends on Q-values of future states as shown here:\n",
        "\n",
        "$$Q(s, a) \\rightarrow \\gamma\\ Q(s', a') + \\gamma^2\\ Q(s'', a'')\\ ...\\ ...\\ ...\\ \\gamma^n\\ Q(s''^{...n}, a'')$$\n",
        "\n",
        "Adjusting the value of gamma will diminish or increase the contribution of future rewards.\n",
        "\n",
        "**Q-Learning Algorithm**\n",
        "\n",
        "1. Initialize Q-values $(Q(s, a))$ arbitrarily for all state-action pairs.\n",
        "2. For life or until learning is stopped....\n",
        "\n",
        "    *   Choose and action $(a)$ in the current state $(s)$ based on the current Q-value estimates\n",
        "\n",
        "    *   Take the action $(a)$ and observe the outcome $(s')$ and reward $(R)$\n",
        "\n",
        "    *   Update $NewQ(s, a) =  Q(s, a) + \\alpha[R(s, a) + \\gamma\\ maxQ^{'}(s', a') - Q(s, a)]$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "To know more about Q-Learning, click [here](https://www.learndatasci.com/tutorials/reinforcement-q-learning-scratch-python-openai-gym/).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q-learning algorithm in general:**\n",
        "\n",
        "- Initialize the Q-table with all zeros\n",
        "- Start exploring actions: For each state, select any one among all possible actions for the current state (S). Methods such as Greedy policy, or Epsilon($\\epsilon$)-greedy policy can be used to select action.\n",
        "- Travel to the next state (S') as a result of that action (a)\n",
        "- For all possible actions from the state (S') select the one with the highest Q-value\n",
        "- Update Q-table values using the equation\n",
        "- Set the next state as the current state\n",
        "- If goal state is reached, then end and repeat the process"
      ],
      "metadata": {
        "id": "rrO74-wUXZfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The Q-table is a matrix where we have a row for every state (500) and a column for every action (6).\n",
        "# It's first initialized to 0, and then values are updated after training.\n",
        "\n",
        "q_table = np.zeros([env.observation_space.n, env.action_space.n])\n",
        "q_table.shape"
      ],
      "metadata": {
        "id": "ECPcZR9Fhqv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now create the training algorithm that will update this Q-table as the agent explores the environment over thousands of episodes."
      ],
      "metadata": {
        "id": "aeXUQIWI5a3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "alpha = 0.1\n",
        "gamma = 0.6\n",
        "epsilon = 0.1\n",
        "episodes = 100000\n",
        "\n",
        "# For plotting metrics\n",
        "all_epochs = []\n",
        "all_penalties = []\n",
        "\n",
        "\n",
        "# Update Q-Table\n",
        "# Iterate over episodes\n",
        "for i in range(1, episodes + 1):\n",
        "\n",
        "    # Reset the environment\n",
        "    # we initialize the first state of the episode\n",
        "    # Initial state and reward\n",
        "    state = env.reset()\n",
        "    reward = 0\n",
        "    done = False\n",
        "\n",
        "    epochs, penalties = 0, 0\n",
        "\n",
        "    while not done:\n",
        "\n",
        "        # Using epsilon-greedy policy for selecting the next action to take\n",
        "        if random.uniform(0, 1) < epsilon:\n",
        "            action = env.action_space.sample()   # Explore action space\n",
        "        else:\n",
        "            action = np.argmax(q_table[state])   # Exploit learned values\n",
        "\n",
        "        # env.step(action): executes the given action and returns four values:\n",
        "        # observation: This is the new observation.\n",
        "        # reward: In this environment, we get a reward of 1.0 at every step, no matter what we do, so the goal is to keep the episode running as long as possible.\n",
        "        # done: This value will be True when the episode is over. After that, the environment must be reset before it can be used again.\n",
        "        # info: This environment-specific dictionary can provide some extra information that we may find useful for debugging or for training.\n",
        "        # For example, in some games it may indicate how many lives the agent has.\n",
        "\n",
        "        # Take action on environment, and get reward and next-state\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "\n",
        "        old_value = q_table[state, action]\n",
        "        next_max = np.max(q_table[next_state])\n",
        "\n",
        "        # Compute the temporal difference\n",
        "        TD = reward + gamma * next_max - old_value\n",
        "\n",
        "        # Update the Q-Value using the Bellman equation\n",
        "        new_value = old_value + alpha * (TD)\n",
        "        q_table[state, action] = new_value\n",
        "\n",
        "        if reward == -10:\n",
        "            penalties += 1\n",
        "\n",
        "        # Our new state is state\n",
        "        state = next_state\n",
        "        epochs += 1\n",
        "\n",
        "    all_epochs.append(epochs)\n",
        "    all_penalties.append(penalties)\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        clear_output(wait=True)\n",
        "        print(f\"Episode: {i}\")\n",
        "\n",
        "print(\"Training finished.\\n\")"
      ],
      "metadata": {
        "id": "rYyciOfMvUOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the Q-table has been established over 100,000 episodes, let's see what the Q-values are at the state illustrated earlier:"
      ],
      "metadata": {
        "id": "sU5m6hFR4s5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q_table[state_]"
      ],
      "metadata": {
        "id": "leAxSlsHvUL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The max Q-value is \"north\" (at index 1), so it looks like Q-learning has effectively learned the best action to take for the state illustrated earlier."
      ],
      "metadata": {
        "id": "s9gmbMJc7OW2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plot metrics"
      ],
      "metadata": {
        "id": "DSxHbXQc5EZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_epochs), len(all_penalties)"
      ],
      "metadata": {
        "id": "bgiX_MG4z8yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(all_epochs, all_penalties, '.')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Penalties\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YVPaczBj0ANL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above plot, it can be seen that most of the episodes were solved within 50 timesteps/epochs, and the episodes who went upto 200 timesteps has acquired high penalties."
      ],
      "metadata": {
        "id": "Iay-gzjZ0U07"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize performance"
      ],
      "metadata": {
        "id": "IwWheRU07nil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To evaluate agent's performance after Q-learning, let's create a function that will return the frames/snapshots of the enviorment as the agent progresses. Also, create functions that will use these frames to create an overall animation."
      ],
      "metadata": {
        "id": "a7_o8XSJy5LR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create function to return frames for animation\n",
        "\n",
        "def render_frames_q_learning(q_table, seed=42):\n",
        "    frames = []\n",
        "    env = gym.make(\"Taxi-v3\", render_mode=\"single_rgb_array\").env\n",
        "    env.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        img = env.render()\n",
        "        frames.append(img)\n",
        "        action = np.argmax(q_table[state])\n",
        "        state, reward, done, info = env.step(action)\n",
        "\n",
        "    env.close()\n",
        "    return frames"
      ],
      "metadata": {
        "id": "C6gM30-kvTHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create functions to plot animation\n",
        "\n",
        "def update_scene(num, frames, patch):\n",
        "    patch.set_data(frames[num])\n",
        "    return patch\n",
        "\n",
        "def plot_animation(frames, repeat=False, interval=40):\n",
        "    fig = plt.figure()\n",
        "    patch = plt.imshow(frames[0])\n",
        "    plt.axis('off')\n",
        "    anim = animation.FuncAnimation(fig, update_scene, fargs=(frames, patch),\n",
        "                                   frames=len(frames), repeat=repeat, interval=interval)\n",
        "    plt.close()\n",
        "    return anim"
      ],
      "metadata": {
        "id": "OexpMHHrw1Sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize animation\n",
        "frames = render_frames_q_learning(q_table, seed=123)     # change the seed value to check performance on different initial states\n",
        "plot_animation(frames)"
      ],
      "metadata": {
        "id": "ChwgMWdKxX3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding Shortest Path using Q-Learning Algorithm"
      ],
      "metadata": {
        "id": "aGfZobU8LbKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shortest path in an undirected graph. **Graphs** are mathematical structures used to model pairwise relations between objects. A graph is made up of vertices which are connected by edges. In an undirected graph, we will find shortest path between two vertices.\n",
        "\n",
        "Q-learning is a model-free reinforcement learning algorithm. The goal of Q-learning is to learn a policy, which tells an agent what action to take under what circumstances. It does not require a model of the environment, and it can handle problems with stochastic transitions and rewards, without requiring adaptations."
      ],
      "metadata": {
        "id": "ZUKmLONbLnfc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkbNNSqBAEyq"
      },
      "source": [
        "### Prepare the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui0PXDME-lwK"
      },
      "source": [
        "Define the dictionaries of states mapped to the indexes and array of actions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "li98TJhV7EVT"
      },
      "source": [
        "\n",
        "\n",
        "![Reinforcement2.PNG](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ABqawSX-mcI"
      },
      "source": [
        "# Define the states\n",
        "location_to_state = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4, 'F':5}\n",
        "\n",
        "# Define the actions\n",
        "actions = [0, 1, 2, 3, 4, 5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JfKFPQzvu8A"
      },
      "source": [
        "Create a reward matrix where we assign rewards as one for all the possible moves which robot can move from the given state to another. Otherwise, we assign reward zero"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdPEFl1E65sI"
      },
      "source": [
        "# Define the reward matrix\n",
        "Reward_matrix = np.array([[0,1,1,0,1,1], [1,0,1,0,0,0], [1,1,0,1,1,0], [0,0,1,0,1,0], [1,0,1,1,0,0], [1,0,0,0,1,0]])\n",
        "print(Reward_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVWzXVF7_t9s"
      },
      "source": [
        "Create a new dictionary for mapping indexes to states which will be used during Q-values computation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbvfBYqpAN3b"
      },
      "source": [
        "# Maps indices to locations\n",
        "state_to_location = {state:location for location, state in location_to_state.items()}\n",
        "print(state_to_location)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LmQZ6Ij-MeI"
      },
      "source": [
        "Initialize the parameters\n",
        "\n",
        "1. Discounting Factor (gamma) is the factor at which the Q-Value gets decremented after each cycle.\n",
        "2. Learning Rate (alpha) is the rate at which the algorithm learns after each cycle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFBN442wS0Os"
      },
      "source": [
        "# Setting the parameters\n",
        "gamma = 0.75 # Discount factor\n",
        "alpha = 0.9 # Learning rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQm73xckDZHY"
      },
      "source": [
        "### Building AI solution with Q-Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO_ajGq69pO6"
      },
      "source": [
        "Temporal Difference (TD) is a sum of reward obtained from moving one state to another state and Discounting factor times the maximum of Q value of the next state concerning the action and Q value of the current state with its action.\n",
        "\n",
        "Update the Q-value of the next corresponding state by the Q value of the previous state and learning rate (alpha) times the temporal difference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xcv9pZ6ZAmWA"
      },
      "source": [
        "# Making a function that returns the path from a starting to the ending location\n",
        "def route(starting_location, ending_location):\n",
        "\n",
        "    # Copy the rewards matrix to new Matrix\n",
        "    R_new = np.copy(Reward_matrix)\n",
        "\n",
        "    # Get the indicies of the ending location\n",
        "    ending_state = location_to_state[ending_location]\n",
        "\n",
        "    # Set the priority of the given ending state to the highest goal\n",
        "    R_new[ending_state, ending_state] = 100\n",
        "\n",
        "    # Initializing Q-Values\n",
        "    Q = np.array(np.zeros([6,6]))\n",
        "\n",
        "    # Q-Learning process\n",
        "    for i in range(1000):\n",
        "        # Pick up a state randomly\n",
        "        current_state = np.random.randint(0,6)\n",
        "\n",
        "        # For traversing through the neighbor locations in the maze\n",
        "        playable_actions = []\n",
        "\n",
        "        # Iterate through the new rewards matrix and get the actions > 0\n",
        "        for j in range(6):\n",
        "            if R_new[current_state, j] > 0:\n",
        "                playable_actions.append(j)\n",
        "\n",
        "        # Pick an action randomly from the list of playable actions and lead to the next state\n",
        "        next_state = np.random.choice(playable_actions)\n",
        "\n",
        "        # Compute the temporal difference. The action here exactly refers to going to the next state\n",
        "        TD = R_new[current_state, next_state] + gamma * Q[next_state, np.argmax(Q[next_state,])] - Q[current_state, next_state]\n",
        "\n",
        "        # Update the Q-Value using the Bellman equation\n",
        "        Q[current_state, next_state] = Q[current_state, next_state] + alpha * TD\n",
        "\n",
        "    # Initialize the optimal route with the starting location\n",
        "    route = [starting_location]\n",
        "\n",
        "    # We do not know about the next location yet, so initialize with the value of starting location\n",
        "    next_location = starting_location\n",
        "\n",
        "    # Get the route\n",
        "    while (next_location != ending_location):\n",
        "        # Fetch the starting state\n",
        "        starting_state = location_to_state[starting_location]\n",
        "\n",
        "        # Fetch the highest Q-value pertaining to starting state\n",
        "        next_state = np.argmax(Q[starting_state,])\n",
        "\n",
        "        # We got the index of the next state. But we need the corresponding letter.\n",
        "        next_location = state_to_location[next_state]\n",
        "        route.append(next_location)\n",
        "\n",
        "        # Update the starting location for the next iteration\n",
        "        starting_location = next_location\n",
        "    return route\n",
        "\n",
        "# Get the optimal route\n",
        "print('Route:')\n",
        "print(route('A', 'D'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do82jrSqrJ3R"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSxOGoFfi9SW",
        "cellView": "form"
      },
      "source": [
        "#@title Q.1. The Q-Learning is a reinforcement learning algorithm used to learn the value of an action in a particular state.\n",
        "Answer1 = \"TRUE\" #@param [\"\",\"TRUE\",\"FALSE\"]\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iUcpkBA26rK"
      },
      "source": [
        "#### Consider the following statements and answer Q2.\n",
        "\n",
        "A. One of the challenges that arise in reinforcement learning, and not in other kinds of learning, is the trade-off between exploration and exploitation.\n",
        "\n",
        "B. To obtain a lot of reward, a reinforcement learning agent must prefer actions that it has tried in the past and found to be e\n",
        "ective in producing reward.\n",
        "\n",
        "C. The agent has to exploit what it already knows in order to obtain reward, but it also has to explore in order make better action selections in the future.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Gxx8RibL_n7k"
      },
      "source": [
        "#@title Q.2. Which of the above statement(s) regarding Reinforcement Learning is/are True ?\n",
        "Answer2 = \"A, B and C\" #@param [\"\",\"Only A\",\"Only C\", \"Only A and C\", \"Only A and B\", \"Only B and C\", \"A, B and C\"]\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMzKSbLIgFzQ"
      },
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"Good and Challenging for me\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjcH1VWSFI2l"
      },
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"na\" #@param {type:\"string\"}\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VBk_4VTAxCM"
      },
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"Yes\" #@param [\"\",\"Yes\", \"No\"]\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH91cL1JWH7m"
      },
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"Somewhat Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8xLqj7VWIKW"
      },
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"Somewhat Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "FzAZHt1zw-Y-",
        "outputId": "496df9b8-ae62-4e73-acb5-ff7e043c9e0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your submission is successful.\n",
            "Ref Id: 2340\n",
            "Date of submission:  17 Aug 2023\n",
            "Time of submission:  21:30:39\n",
            "View your submissions: https://dlfa-iisc.talentsprint.com/notebook_submissions\n"
          ]
        }
      ]
    }
  ]
}